# LLM_Playground
Playground for working with LM Studio and local LLM Integrations

## Overview

Just a place for me to keep code I've worked on for interacting with an LLM hosted locally. Doesn't _need_ to be hosted locally, but that's easy for now.

## Powershell

I'd _love_ to take the output of a `Get-Service` or other powershell cmdlet and send it to an LLM for analysis/formatting/work. Dealing with all the different object types that can come back from a `Get-*` command is daunting. There are also issues with context size for smaller locally-hosted LLMs.